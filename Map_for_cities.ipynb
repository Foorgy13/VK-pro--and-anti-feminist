{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройки + загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the country table\n",
    "country_table_path = 'STRANY.txt'\n",
    "country_df = pd.read_csv(country_table_path, delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "# Load the main file\n",
    "df = pd.read_csv('Merged_fem_groups_with_user_chars_city_names.csv', low_memory=False)\n",
    "\n",
    "# Check the structure of the loaded data\n",
    "print(country_df.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка и геокодинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city_names это уникальные названия городов из моего файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'city.name' column\n",
    "city_names = df['city.name']\n",
    "\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = len(city_names)\n",
    "\n",
    "# Drop entries where city name is missing\n",
    "city_names = city_names.dropna()\n",
    "\n",
    "# Number of entries with specified city\n",
    "entries_with_city = len(city_names)\n",
    "\n",
    "# Calculate the share of people who specified their city\n",
    "share_with_city = (entries_with_city / total_entries) * 100\n",
    "print(f\"Share of people who specified their city: {share_with_city:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле ```STRANY.txt``` есть список названий стран (полных и сокрвщенных) и их переводы на английский, создадим словарь для того, чтобы с его помощью перевести названия стран из документа, который у нас получился из ВК."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря для перевода\n",
    "# Используем как `name`, так и `fullname` в качестве ключей\n",
    "translation_dict = {}\n",
    "for _, row in country_df.iterrows():\n",
    "    if pd.notna(row['name']):\n",
    "        translation_dict[row['name'].strip()] = row['english'].strip()\n",
    "    if pd.notna(row['fullname']):\n",
    "        translation_dict[row['fullname'].strip()] = row['english'].strip()\n",
    "\n",
    "# Функция перевода страны с использованием словаря\n",
    "def translate_country_name(russian_name):\n",
    "    if not russian_name or pd.isna(russian_name):\n",
    "        return ''  # Возвращаем пустую строку для пропусков\n",
    "    return translation_dict.get(russian_name.strip(), russian_name)  # Если нет перевода, возвращаем оригинал\n",
    "\n",
    "# Извлечение названий стран\n",
    "def extract_country_name(country_str):\n",
    "    try:\n",
    "        country_dict = ast.literal_eval(country_str)\n",
    "        return country_dict.get('title', None)  # Извлекаем поле 'title', если оно есть\n",
    "    except (ValueError, SyntaxError, KeyError, AttributeError) as e:\n",
    "        print(f\"Error parsing country string: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Название страны в ```Merged_fem_groups_with_user_chars_city_names.csv``` содержится в колонке `country` в формате словаря, из этого словаря нам нужно только поле `title` с, собственно, названием страны (на русском). Далее мы переводим это название с помощью нашего файла с сайта Лебедева: https://www.artlebedev.ru/country-list/tab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем название страны в отдельную колонку\n",
    "df['country_name'] = df['country'].apply(extract_country_name)\n",
    "\n",
    "# Пропуски оставляем пустыми строками\n",
    "df['country_name'] = df['country_name'].fillna('')\n",
    "\n",
    "# Применяем перевод\n",
    "df['country_translated'] = df['country_name'].apply(translate_country_name)\n",
    "\n",
    "# Проверяем результаты\n",
    "print(df[['country', 'country_name', 'country_translated']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более простой работы от оригинального датафрейма со всеми пользователями оставляем только табличку с их городами и странами (где есть). Дубликаты городов для визуализации нам не нужны, избавляемся от них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names_and_countries = df[['city.name', 'country_translated']]\n",
    "\n",
    "unique_city_names = city_names_and_countries.drop_duplicates(subset='city.name')\n",
    "print(f\"Number of unique cities: {len(unique_city_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации нам нужно *геокодировать* наши города, то есть нужны их широта и долгота. Это сделано с помощью пакета `geopy`, он будет кодировать города с использованием их стран (где есть). Надеюсь, это поможет избежать поиска пермского города Оса во Франции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize geolocator with a user agent\n",
    "geolocator = Nominatim(user_agent=\"city_mapper\")\n",
    "\n",
    "# Rate limiter to respect the geocoding service's rate limits\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Prepare dictionaries to store results\n",
    "geocoded_data = {}\n",
    "\n",
    "# Geocode each unique city name with country information\n",
    "for index, row in tqdm(unique_city_names.iterrows(), desc=\"Geocoding cities\", total=unique_city_names.shape[0]):\n",
    "    city = row['city.name']\n",
    "    country = row['country_translated']\n",
    "    try:\n",
    "        # Include country name in the geocoding request\n",
    "        location = geocode(f\"{city}, {country}\")\n",
    "        if location:\n",
    "            # Extract country from the address\n",
    "            address = location.raw.get('display_name', '')\n",
    "            country_extracted = address.split(',')[-1].strip()\n",
    "            geocoded_data[city] = {\n",
    "                'latitude': location.latitude,\n",
    "                'longitude': location.longitude,\n",
    "                'country': country_extracted\n",
    "            }\n",
    "        else:\n",
    "            geocoded_data[city] = {\n",
    "                'latitude': None,\n",
    "                'longitude': None,\n",
    "                'country': None\n",
    "            }\n",
    "    except Exception as e:\n",
    "        geocoded_data[city] = {\n",
    "            'latitude': None,\n",
    "            'longitude': None,\n",
    "            'country': None\n",
    "        }\n",
    "\n",
    "# Convert geocoded_data to DataFrame\n",
    "geocoded_df = pd.DataFrame.from_dict(geocoded_data, orient='index').reset_index()\n",
    "geocoded_df.rename(columns={'index': 'city.name'}, inplace=True)\n",
    "\n",
    "print(f\"Total unique geocoded cities: {len(geocoded_df)}\")\n",
    "print(geocoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city_names_df это датафрейм с уникальными городами из моего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert geocoded_data to DataFrame\n",
    "geocoded_df = pd.DataFrame.from_dict(geocoded_data, orient='index')\n",
    "geocoded_df.reset_index(inplace=True)\n",
    "geocoded_df.rename(columns={'index': 'city.name'}, inplace=True)\n",
    "\n",
    "# Merge the geocoded data back to the original data\n",
    "city_names_df = city_names.to_frame().reset_index(drop=True)\n",
    "merged_df = city_names_df.merge(geocoded_df, on='city.name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почистим/причешем немного данные & посчитаем, у скольких людей указан русский город (среди всех людей с указанным городом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total entries with valid geocoding results\n",
    "valid_geocoded_entries = merged_df.dropna(subset=['latitude', 'longitude', 'country'])\n",
    "\n",
    "# Number of entries with Russian cities\n",
    "entries_with_russian_city = valid_geocoded_entries[valid_geocoded_entries['country'] == 'Россия'].shape[0]\n",
    "\n",
    "# Calculate the share\n",
    "share_with_russian_city = (entries_with_russian_city / entries_with_city) * 100\n",
    "print(f\"Share of people who specified a Russian city: {share_with_russian_city:.2f}% out of the ones with the city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_geocoded_entries  это датафрейм, в котором оставлены только уникальные города, их страны и координаты, полученные *геокодированием*. Загрузим Васин датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset\n",
    "df_new = pd.read_stata('socialmedia_data_main.dta')\n",
    "\n",
    "# Extract the 'city_name_eng' column\n",
    "new_city_names = df_new['city_name_eng']\n",
    "new_coords = df_new[['lon', 'lat']]\n",
    "\n",
    "# Handle missing values\n",
    "new_city_names = new_city_names.dropna()\n",
    "\n",
    "# Total number of entries in the new dataset\n",
    "total_new_entries = len(new_city_names)\n",
    "\n",
    "# Display the first few city names\n",
    "print(\"First few city names from the new dataset:\")\n",
    "print(new_city_names.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый датасет с городами и их координатами по Васиным данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geocoded_df = pd.concat([new_coords, new_city_names], axis=1)\n",
    "new_geocoded_df['country'] = 'Russian Federation' # все васины гороа из России\n",
    "new_geocoded_df = new_geocoded_df.drop_duplicates(subset='city_name_eng') #убираем дубликаты городов\n",
    "# Rename columns\n",
    "new_geocoded_df.rename(columns={\n",
    "    'city_name_eng': 'city.name',\n",
    "    'lat': 'latitude',\n",
    "    'lon': 'longitude'\n",
    "}, inplace=True) #Переназываем столбцы для единообразия с предыдущими"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем мои и васины данные в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert new_geocoded_data to DataFrame\n",
    "#new_geocoded_df = pd.DataFrame.from_dict(new_geocoded_data, orient='index')\n",
    "#new_geocoded_df.reset_index(inplace=True)\n",
    "#new_geocoded_df.rename(columns={'index': 'city.name'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Combine with the previously geocoded data\n",
    "combined_geocoded_df = pd.concat([geocoded_df, new_geocoded_df], ignore_index=True)\n",
    "\n",
    "# Remove duplicates in case some cities overlapped\n",
    "combined_geocoded_df.drop_duplicates(subset='city.name', inplace=True)\n",
    "\n",
    "# Drop entries where geocoding failed\n",
    "combined_geocoded_df = combined_geocoded_df.dropna(subset=['latitude', 'longitude', 'country'])\n",
    "\n",
    "print(f\"Total unique geocoded cities: {len(combined_geocoded_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем первый финальный датасет для работы с картой, не забываем указать маркер, что данные от меня 'First Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming city_names_df contains the city names from the first dataset\n",
    "# Merge geocoded data with the first dataset\n",
    "merged_df_first = city_names_df.merge(\n",
    "    combined_geocoded_df[['city.name', 'latitude', 'longitude', 'country']],\n",
    "    left_on='city.name',\n",
    "    right_on='city.name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add a column to indicate the dataset source\n",
    "merged_df_first['dataset'] = 'First Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось что-то такое:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city.name   latitude  longitude country        dataset\n",
    "0  Saint Petersburg  59.960674  30.158655  Россия  First Dataset\n",
    "1  Saint Petersburg  59.960674  30.158655  Россия  First Dataset\n",
    "2  Saint Petersburg  59.960674  30.158655  Россия  First Dataset\n",
    "3  Saint Petersburg  59.960674  30.158655  Россия  First Dataset\n",
    "4  Saint Petersburg  59.960674  30.158655  Россия  First Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "latitude     longitude\n",
    "count  39523.000000  39523.000000\n",
    "mean      55.449206     37.748792\n",
    "std        7.107904     26.246781\n",
    "min      -51.778836   -176.174022\n",
    "25%       54.726141     30.158655\n",
    "50%       55.625578     35.895242\n",
    "75%       59.960674     37.729777\n",
    "max       78.065362    177.506092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_cities = merged_df_first['city.name'].value_counts().head(10)\n",
    "print(top_10_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city.name\n",
    "Saint Petersburg    14428\n",
    "Moscow               8738\n",
    "Kyiv                  615\n",
    "Yekaterinburg         415\n",
    "Novosibirsk           406\n",
    "Minsk                 403\n",
    "Rostov-on-Don         296\n",
    "Krasnodar             278\n",
    "Nizhny Novgorod       278\n",
    "Kazan                 262\n",
    "Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое делаем для Васиных данных, его метка 'Second Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the city names DataFrame for the new dataset\n",
    "new_city_names_df = new_city_names.to_frame().reset_index(drop=True)\n",
    "new_city_names_df.rename(columns={'city_name_eng': 'city.name'}, inplace=True)\n",
    "\n",
    "# Merge geocoded data with the new dataset\n",
    "merged_df_new = new_city_names_df.merge(\n",
    "    combined_geocoded_df[['city.name', 'latitude', 'longitude', 'country']],\n",
    "    left_on='city.name',\n",
    "    right_on='city.name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add a column to indicate the dataset source\n",
    "merged_df_new['dataset'] = 'Second Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось что-то вот такое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city.name   latitude  longitude country         dataset\n",
    "0        Barnaul  53.347549  83.778845  Россия  Second Dataset\n",
    "1         Alejsk  52.500000  82.783333  Россия  Second Dataset\n",
    "2          Bijsk  52.516666  85.166664  Россия  Second Dataset\n",
    "3        Zarinsk  53.707915  84.934861  Россия  Second Dataset\n",
    "4  Kamen'-na-Obi  53.799999  81.333336  Россия  Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_cities = merged_df_new['city.name'].value_counts().head(10)\n",
    "print(top_10_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "latitude   longitude\n",
    "count  624.000000  624.000000\n",
    "mean    54.240179   56.832416\n",
    "std      5.065075   27.300984\n",
    "min     42.057858   19.916666\n",
    "25%     52.049999   38.817731\n",
    "50%     54.995445   46.141666\n",
    "75%     56.800016   61.636249\n",
    "max     69.333336  158.649994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склеми финальные датасеты для карты (те, что с метками), **удалим города, которые не вышло закодировать**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets\n",
    "merged_df_combined = pd.concat([merged_df_first, merged_df_new], ignore_index=True)\n",
    "\n",
    "# Drop entries without geocoding information\n",
    "merged_df_combined = merged_df_combined.dropna(subset=['latitude', 'longitude', 'country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рисуем карту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Calculate the central point for the map\n",
    "map_center = [merged_df_combined['latitude'].mean(), merged_df_combined['longitude'].mean()]\n",
    "\n",
    "# Create a Folium map\n",
    "city_map = folium.Map(location=map_center, zoom_start=2)\n",
    "\n",
    "# Define colors for each dataset\n",
    "dataset_colors = {\n",
    "    'First Dataset': 'blue',\n",
    "    'Second Dataset': 'green'\n",
    "}\n",
    "\n",
    "# Add city markers to the map\n",
    "for idx, row in merged_df_combined.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row['latitude'], row['longitude']),\n",
    "        radius=3,\n",
    "        popup=f\"{row['city.name']}, {row['country']} ({row['dataset']})\",\n",
    "        color=dataset_colors.get(row['dataset'], 'gray'),\n",
    "        fill=True,\n",
    "        fill_color=dataset_colors.get(row['dataset'], 'gray')\n",
    "    ).add_to(city_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "city_map.save('combined_city_map_2025.html')\n",
    "print(\"Combined map has been saved to 'combined_city_map.html'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
