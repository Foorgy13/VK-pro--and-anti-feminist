{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пипы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Путь к папке с CSV файлами\n",
    "folder_path = '/Users/olgafoorgy/Documents/Documents - Ноутбук — Ольга/Andrey Simonov/useful users'\n",
    "\n",
    "# Используем glob для получения всех файлов с расширением .csv в папке\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "csv_files = csv_files#[0:2]\n",
    "# Загрузка таблицы пользователей и групп (используем pandas)\n",
    "user_groups = pd.read_csv('user|group just FEM subs.csv', dtype={'id': 'int64'}, usecols=['id'])\n",
    "merged = user_groups.copy()  # just the id for future processing ease\n",
    "trial = 1\n",
    "# Пройдем по всем файлам CSV в папке\n",
    "for file in csv_files:\n",
    "    print(\"Processing file \", file)\n",
    "    # Загрузка характеристик пользователей\n",
    "    user_features = pd.read_csv(file, dtype={'id': 'int64'},low_memory=False)\n",
    "    \n",
    "    # Объединение таблиц по столбцу 'id' с добавлением суффиксов для предотвращения дублирования\n",
    "    merged = merged.merge(user_features, how='left', on='id', suffixes=('', '_new'))\n",
    "    \n",
    "    # Проходим по всем столбцам с суффиксами и объединяем их\n",
    "    for column in user_features.columns:\n",
    "        if column != 'id':  # Пропускаем столбец 'id'\n",
    "            if column + '_new' in merged.columns:\n",
    "                # Заполняем NaN значениями из _new, если столбец существует\n",
    "                merged[column] = merged[column].fillna(merged[column + '_new'])\n",
    "                merged = merged.drop(columns=[column + '_new'])  # Убираем временный столбец с суффиксом\n",
    "\n",
    "    # Если нужно, можно также переименовать оставшиеся столбцы, чтобы убрать суффикс\n",
    "    merged = merged.rename(columns=lambda x: x.replace('_new', ''))\n",
    "\n",
    "# Сохранение итогового результата в CSV\n",
    "merged.to_csv(f'Merged_fem_groups_with_user_chars_{trial}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = pd.read_csv('user|group just FEM subs.csv', dtype={'id': 'int64'})\n",
    "merged = merged.merge(user_groups, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у меня есть таблица с юзерами группами и характеристиками юзеров (напомню, юзеры по строкам). Мне нужно сделать сводную таблицу, которая показывает, сколько у каждой группы юзеров из каждого города (city.id), отдельно такая же таблица для каждого пола (sex), а также похожие саммари таблички по полям 'personal.alcohol', 'personal.langs', 'personal.life_main', 'personal.people_main', 'personal.political', 'personal.religion', 'personal.smoking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vk_api\n",
    "# Read the access token from the file\n",
    "with open('/Users/olgafoorgy/Documents/Documents - Ноутбук — Ольга/groups/TOKEN VK') as f:\n",
    "    access_token = f.read().strip()\n",
    "\n",
    "# Initialize VK session\n",
    "vk_session = vk_api.VkApi(token=access_token)\n",
    "vk = vk_session.get_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique city IDs from the dataframe\n",
    "unique_city_ids = merged['city.id'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vk_api\n",
    "from tqdm import tqdm  # Для отображения прогресса\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Fetch city names from VK API\n",
    "city_mapping = {}\n",
    "for city_id in tqdm(unique_city_ids, desc=\"Fetching city names\"):\n",
    "    try:\n",
    "        # Call VK API to get city details\n",
    "        response = vk.database.getCitiesById(city_ids=city_id)\n",
    "        if response:\n",
    "            city_mapping[city_id] = response[0]['title']  # Extract city name\n",
    "        else:\n",
    "            city_mapping[city_id] = None  # Handle case where city is not found\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching city ID {city_id}: {e}\")\n",
    "        city_mapping[city_id] = None\n",
    "    #time.sleep(0.35)  # Pause to respect VK API rate limits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace city IDs with names in the dataframe\n",
    "merged['city.name'] = merged['city.id'].map(city_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a file (optional)\n",
    "merged.to_csv('Merged_fem_groups_with_user_chars_city_names.csv', index=False)\n",
    "\n",
    "# Preview the updated dataframe\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если тут работу остановили, то можно заново загрузить merged уже из csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged = pd.read_csv('Merged_fem_groups_with_user_chars_city_names.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбросим группы, не подходящие (не фем/локальные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns=['80728963', '153276634', '189672959'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остались колонки 'id', 'bdate', 'country', 'facebook', 'facebook_name', 'first_name',\n",
    "       'home_town', 'instagram', 'last_name', 'livejournal', 'screen_name',\n",
    "       'sex', 'twitter', 'city.id', 'city.title', 'personal.alcohol',\n",
    "       'personal.inspired_by', 'personal.langs', 'personal.life_main',\n",
    "       'personal.people_main', 'personal.political', 'personal.religion',\n",
    "       'personal.smoking', '81914161', '190884646', '96917976', '204732875',\n",
    "       '198043329', '159437367', '74599974', '195772623', '73197614',\n",
    "       '73837757', '87819738', '114487519', '65878810', '128501486',\n",
    "       '204172284', '209222517', '189672959', '163233491', '225770630',\n",
    "       'city.name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
